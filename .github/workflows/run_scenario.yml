name: Run Avayam Benchmark
on:
  push:
    paths:
      - 'scenario.toml'  # Trigger when config changes
  workflow_dispatch:      # Allow manual trigger

permissions:
  contents: write

jobs:
  run-benchmark:
    runs-on: ubuntu-latest
    
    services:
      # Green Agent (The Judge)
      green-agent:
        image: amdravidranjan/avayam-green-agent:latest
        ports:
          - 8000:8000
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      # Purple Agent (The Participant)
      # Usually this would be dynamic, but for this repo it's fixed
      participant-agent:
        image: amdravidranjan/avayam-purple-agent:latest
        ports:
          - 8001:8000 
        env:
          # If the user sets this secret, the agent uses LLM. Otherwise fallback to Heuristic.
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Runner Dependencies
        run: pip install requests

      - name: Run Benchmark Script
        run: python scripts/runner.py
        env:
          # Optional: Override Agent ID if needed from GitHub Vars
          AGENT_ID: "019c17ab-21f2-78a3-a404-24054d5c73b8"

      - name: Commit Results
        run: |
          git config --global user.name "Avayam Bot"
          git config --global user.email "bot@avayam.dev"
          git add results/*.json
          git commit -m "Automated Benchmark Result $(date)" || echo "No changes to commit"
          git pull --rebase origin main
          git push
